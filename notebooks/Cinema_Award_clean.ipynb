{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import sys \n",
    "sys.path.append(\"../\") \n",
    "import src.support as sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the clean csv's into a Data Frame\n",
    "\n",
    "df_oscar = pd.read_csv(\"..\\data\\Oscar_clean.csv\")\n",
    "df_goldenglobes = pd.read_csv(\"..\\data\\Golden_Globes_clean.csv\")\n",
    "df_sag = pd.read_csv(\"..\\data\\SAG_clean.csv\")\n",
    "df_cca = pd.read_csv(\"..\\data\\CCA_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(684, 722, 355, 481)\n"
     ]
    }
   ],
   "source": [
    "# Create a tuple 'count' that contains the number of unique films in each of the specified dataframes\n",
    "\n",
    "count = (len(df_oscar[\"film\"].unique()), len(df_goldenglobes[\"film\"].unique()), \n",
    "        len(df_sag[\"film\"].unique()), len(df_cca[\"film\"].unique()))\n",
    "\n",
    "# Print the tuple\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 5 csv in one\n",
    "\n",
    "merged_df = pd.concat([df_oscar, df_goldenglobes, df_sag, df_cca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the columns we need to standarize\n",
    "\n",
    "merged_df[\"category\"] = sp.standarize_title(merged_df, \"category\")\n",
    "merged_df[\"film\"] = sp.standarize_title(merged_df, \"film\")\n",
    "\n",
    "# Strip every space contained in film\n",
    "\n",
    "merged_df[\"film\"] = [i.strip() for i in merged_df[\"film\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "\n",
    "merged_df = merged_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column I donÂ´t need\n",
    "\n",
    "merged_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "merged_df.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN in the awards with No\n",
    "\n",
    "merged_df[\"oscar\"] = merged_df[\"oscar\"].fillna(\"No\")\n",
    "merged_df[\"golden_globe\"] = merged_df[\"golden_globe\"].fillna(\"No\")\n",
    "merged_df[\"sag\"] = merged_df[\"sag\"].fillna(\"No\")\n",
    "merged_df[\"cca\"] = merged_df[\"cca\"].fillna(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any duplicate\n",
    "\n",
    "merged_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year_ceremony    0\n",
       "category         0\n",
       "name             0\n",
       "film             0\n",
       "oscar            0\n",
       "golden_globe     0\n",
       "sag              0\n",
       "cca              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any null value\n",
    "\n",
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the selected film name with the new correct one\n",
    "\n",
    "merged_df[\"film\"] = merged_df['film'].replace('Birdcage, The', 'The Birdcage')\n",
    "merged_df[\"film\"] = merged_df['film'].replace('Silence Of The Lambs, The', 'The Silence Of The Lambs')\n",
    "merged_df[\"film\"] = merged_df['film'].replace('Fighter, The', 'The Fighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the unique values from the \"film\" column as an appendix\n",
    "\n",
    "film_list = merged_df[\"film\"].unique()\n",
    "\n",
    "# Initialize an empty list to store the similar films\n",
    "\n",
    "similar_films = []\n",
    "\n",
    "# Loop through each film in the film_list \n",
    "\n",
    "for i, film1 in enumerate(film_list):\n",
    "    year1 = merged_df[merged_df[\"film\"] == film1][\"year_ceremony\"].values[0]\n",
    "    for film2, year2 in [(film, merged_df[merged_df[\"film\"] == film][\"year_ceremony\"].values[0]) for film in film_list[i+1:]]:\n",
    "        ratio = fuzz.token_set_ratio(film1, film2)\n",
    "\n",
    "        # Check if the similarity is greater than or equal to 80 and the year is the same\n",
    "\n",
    "        if ratio >= 80 and year1 == year2:\n",
    "            similar_films.append((film1, film2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of indexes to delete, because they are not the same movie, I check for their index first\n",
    "\n",
    "del_values = [41, 58, 81, 95]\n",
    "\n",
    "# Use a list comprehension to create a new list containing only the elements you want to delete\n",
    "# The enumerate function returns a tuple containing the index and value of each element in the similar_films list\n",
    "# The condition in the if statement filters out the elements at the indexes specified in the del_values list\n",
    "\n",
    "similar_films1 = [film for i, film in enumerate(similar_films) if i not in del_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the similar films into two separate lists\n",
    "\n",
    "first_films, second_films = zip(*similar_films1)\n",
    "\n",
    "# Replace the names so, all are the same\n",
    "\n",
    "merged_df[\"film\"] = merged_df['film'].replace(first_films, second_films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to csv and store it in data folder\n",
    "\n",
    "merged_df.to_csv(\"..\\data\\Cinema_Awards.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50cc79e049fc694ec4a617632d3f3b416d701e5c7d1bd2dcb3b8bc06996fdedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
